"""
é—´è´¨ç—…MDTæ™ºèƒ½è¯Šç–—ç³»ç»Ÿ - Streamlitç•Œé¢
ä¸“ä¸šçš„å¤šå­¦ç§‘å›¢é˜Ÿè®¨è®ºå¹³å°ï¼Œä¸ºé—´è´¨æ€§è‚ºç—…è¯Šç–—æä¾›æ™ºèƒ½åŒ–æ”¯æŒ
"""

import streamlit as st
import time
import json
import markdown
import html
import re
import glob
from datetime import datetime
from typing import Dict, Any, List, Optional, Generator
import threading
import queue
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from mdt_system.orchestrator import MDTOrchestrator
from utils.config import config
from test_data import get_test_mdt_result
import logging
from prompts import list_prompts as _list_prompts  # type: ignore
from prompts import reload_all_prompts as _reload_all_prompts  # type: ignore
from prompts import get_prompt as _get_prompt  # type: ignore
from prompts.loader import safe_format as _safe_format, get_prompt_meta as _get_prompt_meta  # type: ignore
from knowledge.vector_store import get_knowledge_store  # æƒ°æ€§è·å–å®ä¾‹

# ä½¿ç”¨ Streamlit èµ„æºçº§ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡è„šæœ¬é‡è·‘éƒ½é‡å¤åˆå§‹åŒ–
@st.cache_resource(show_spinner=False)
def _get_cached_knowledge_store():
    return get_knowledge_store()

# è½»é‡å®ä¾‹ï¼ˆå†…éƒ¨æƒ°æ€§åŠ è½½ç´¢å¼•/åµŒå…¥ï¼‰ï¼Œé¿å…æ¨¡å—å¯¼å…¥æ—¶é˜»å¡
knowledge_store = _get_cached_knowledge_store()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é—´è´¨ç—…MDTæ™ºèƒ½ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS - ä¸ºä¸“ä¸šMDTç•Œé¢ä¼˜åŒ–
st.markdown("""
<style>
    /* éšè—é»˜è®¤UI */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}

    /* èƒŒæ™¯ä¸å®¹å™¨ */
    .stApp {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        max-width: 100%;
    }
    
    /* å¡ç‰‡æ ·å¼ - èåˆåŸ stream + ç»Ÿä¸€é£æ ¼ */
    .stream-card {
        background: linear-gradient(145deg, #ffffff, #f8f9fa);
        border-radius: 16px;
        padding: 24px;
        margin-bottom: 24px;
        box-shadow: 0 8px 24px rgba(0,0,0,0.08);
        border: 1px solid rgba(0,0,0,0.06);
        position: relative;
        overflow: hidden;
        transition: all 0.3s ease;
    }
    
    .stream-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 12px 32px rgba(0,0,0,0.12);
    }
    
    /* ä¸“å®¶å¤´åƒåŒºåŸŸ - ä¸‰æ å¼å¸ƒå±€ */
    .expert-header {
        display: flex;
        align-items: center;
        margin-bottom: 20px;
        padding-bottom: 16px;
        border-bottom: 2px solid rgba(0,0,0,0.05);
    }
    
    .expert-avatar {
        width: 60px;
        height: 60px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        color: white;
        font-weight: bold;
        margin-right: 16px;
        font-size: 24px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        border: 3px solid white;
    }
    
    .expert-info {
        flex: 1;
    }
    
    .expert-info h3 {
        margin: 0 0 4px 0;
        color: #2c3e50;
        font-size: 20px;
        font-weight: 600;
    }
    
    .expert-info p {
        margin: 0;
        color: #7f8c8d;
        font-size: 14px;
        font-weight: 500;
    }
    
    /* åŠ¨æ€å†…å®¹åŒºåŸŸ */
    .stream-content {
        min-height: 120px;
        line-height: 1.7;
        font-size: 15px;
        color: #34495e;
        background: rgba(255,255,255,0.7);
        border-radius: 12px;
        padding: 20px;
        margin-top: 12px;
        /* æ–°å¢ï¼šé™åˆ¶å¡ç‰‡é«˜åº¦å¹¶å…è®¸å†…éƒ¨æ»šåŠ¨ */
        max-height: 340px;
        overflow-y: auto;
        scrollbar-width: thin; /* Firefox */
        scrollbar-color: rgba(0,0,0,0.25) transparent;
    }

    /* WebKitæ»šåŠ¨æ¡ç¾åŒ– */
    .stream-content::-webkit-scrollbar {
        width: 8px;
    }
    .stream-content::-webkit-scrollbar-track {
        background: transparent;
    }
    .stream-content::-webkit-scrollbar-thumb {
        background: rgba(0,0,0,0.18);
        border-radius: 4px;
    }
    .stream-content::-webkit-scrollbar-thumb:hover {
        background: rgba(0,0,0,0.33);
    }
    
    /* æ‰“å­—æœºæ•ˆæœ */
    .typing-indicator {
        display: inline-block;
        animation: pulse 1.5s infinite;
        color: #3498db;
        font-weight: bold;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; transform: scale(1); }
        50% { opacity: 0.6; transform: scale(1.1); }
    }
    
    /* çŠ¶æ€æŒ‡ç¤ºå™¨ - å³ä¸Šè§’å¾½ç«  */
    .status-indicator {
        position: absolute;
        top: 20px;
        right: 20px;
        padding: 8px 16px;
        border-radius: 20px;
        font-size: 12px;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 0.5px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .status-thinking {
        background: linear-gradient(135deg, #f39c12, #e67e22);
        color: white;
    }
    
    .status-typing {
        background: linear-gradient(135deg, #27ae60, #2ecc71);
        color: white;
        animation: pulse 2s infinite;
    }
    
    .status-complete {
        background: linear-gradient(135deg, #3498db, #2980b9);
        color: white;
    }
    
    /* é˜¶æ®µè¿›åº¦å¡ç‰‡ */
    .phase-progress {
        background: linear-gradient(135deg, #667eea, #764ba2);
        border-radius: 16px;
        padding: 24px;
        margin: 24px 0;
        color: white;
        text-align: center;
        box-shadow: 0 8px 24px rgba(102, 126, 234, 0.3);
    }
    
    .phase-progress h3 {
        margin: 0 0 8px 0;
        font-size: 24px;
        font-weight: 700;
    }
    
    .phase-progress p {
        margin: 0;
        font-size: 16px;
        opacity: 0.9;
    }
    
    /* ä¸“å®¶å›å¤æ–‡æœ¬å®¹å™¨ */
    .stream-text {
        white-space: pre-wrap;
        word-wrap: break-word;
    }
    
    /* å“åº”å¼åˆ— */
    @media (max-width: 768px) {
        .main .block-container {
            padding-left: 1rem;
            padding-right: 1rem;
        }
        
        .stream-card {
            margin: 8px 0;
            padding: 16px;
        }
        
        .expert-header {
            flex-direction: column;
            text-align: center;
        }
        
        .expert-avatar {
            margin: 0 0 12px 0;
        }
        
        .stream-content {
            margin-top: 16px;
            padding: 16px;
        }
        
        .status-indicator {
            position: static;
            margin: 12px 0 0 0;
            display: inline-block;
        }
    }
    
    /* é¡µé¢æ ‡é¢˜å’Œå¸ƒå±€ */
    .main-title {
        background: linear-gradient(135deg, #667eea, #764ba2);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        text-align: center;
        font-size: 36px;
        font-weight: 800;
        margin: 24px 0;
        letter-spacing: -0.5px;
    }
    
    .section-divider {
        height: 2px;
        background: linear-gradient(90deg, transparent, #667eea, transparent);
        margin: 32px 0;
        border: none;
    }
    
    /* åŠ è½½åŠ¨ç”» */
    .loading-spinner {
        display: inline-block;
        width: 20px;
        height: 20px;
        border: 3px solid #f3f3f3;
        border-top: 3px solid #3498db;
        border-radius: 50%;
        animation: spin 1s linear infinite;
        margin-right: 8px;
    }
    
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    
    /* æŒ‡æ ‡å¡ç‰‡ / ç»“æœæ€»ç»“å¡ç‰‡ */
    .metric-card {
        background: white;
        padding: 20px;
        border-radius: 15px;
        text-align: center;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        margin: 10px 0;
    }
    .summary-card {
        background: linear-gradient(135deg, #74b9ff, #0984e3);
        border-radius: 16px;
        padding: 32px;
        margin: 24px 0;
        color: white;
        box-shadow: 0 12px 32px rgba(116, 185, 255, 0.3);
    }
    
    .summary-card h2 {
        margin: 0 0 16px 0;
        font-size: 28px;
        font-weight: 700;
    }
    
    .summary-card .content {
        font-size: 16px;
        line-height: 1.8;
        opacity: 0.95;
    }

    /* é™æ€ç»“æœå±•ç¤ºå¡ç‰‡å¯æ»šåŠ¨åŒºåŸŸ */
    .card-scroll {
        max-height: 340px;
        overflow-y: auto;
        padding-right: 4px;
        scrollbar-width: thin;
        scrollbar-color: rgba(0,0,0,0.25) transparent;
    }
    .card-scroll::-webkit-scrollbar { width: 8px; }
    .card-scroll::-webkit-scrollbar-track { background: transparent; }
    .card-scroll::-webkit-scrollbar-thumb { background: rgba(0,0,0,0.18); border-radius:4px; }
    .card-scroll::-webkit-scrollbar-thumb:hover { background: rgba(0,0,0,0.33); }
    
    /* é”™è¯¯æç¤º */
    .error-message {
        background: linear-gradient(135deg, #e74c3c, #c0392b);
        color: white;
        padding: 20px;
        border-radius: 12px;
        margin: 16px 0;
        box-shadow: 0 6px 20px rgba(231, 76, 60, 0.3);
    }
    
    .error-message .icon {
        font-size: 24px;
        margin-right: 12px;
        vertical-align: middle;
    }

    /* ===== æ–°å¢ï¼šåæœŸé˜¶æ®µå…¨å®½å¡ç‰‡ä¸ä¸“ä¸šMarkdownæ ·å¼ ===== */
    .phase-wide-card {
        background: linear-gradient(145deg,#ffffff,#f6f7fb);
        border: 1px solid rgba(0,0,0,0.06);
        border-radius: 18px;
        padding: 28px 34px;
        margin: 26px 0 34px 0;
        box-shadow: 0 10px 30px -5px rgba(0,0,0,0.08);
        position: relative;
        overflow: hidden;
    }
    .phase-wide-card:before {
        content: "";
        position: absolute;
        top:0;left:0;right:0;height:6px;
        background: linear-gradient(90deg,#667eea,#764ba2,#4facfe);
        opacity:.85;
    }
    .phase-wide-card h3.section-title {
        margin:0 0 14px 0;
        font-size:22px;
        font-weight:700;
        background: linear-gradient(135deg,#2c3e50,#667eea);
        -webkit-background-clip:text; -webkit-text-fill-color:transparent;
        letter-spacing:.5px;
    }
    .phase-wide-card .sub-note {margin:0 0 18px 0;color:#566176;font-size:14px;}
    .phase-wide-card .metric-badges {display:flex;flex-wrap:wrap;gap:10px;margin:6px 0 18px 0;}
    .phase-wide-card .metric-badge {background:#eef1f7;padding:8px 14px;border-radius:30px;font-size:12px;font-weight:600;color:#415061;box-shadow:0 2px 4px rgba(0,0,0,0.05);}    

    /* ä¸“ä¸šMarkdownå®¹å™¨ */
    .mdt-md {font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Arial,'PingFang SC','Hiragino Sans GB','Microsoft YaHei',sans-serif;line-height:1.7;font-size:15px;color:#2c3e50;}
    .mdt-md h1,.mdt-md h2,.mdt-md h3,.mdt-md h4 {font-weight:700;line-height:1.25;margin:1.4em 0 .6em;position:relative;}
    .mdt-md h1 {font-size:1.9rem;border-bottom:2px solid #e0e4ec;padding-bottom:.4rem;}
    .mdt-md h2 {font-size:1.55rem;border-left:6px solid #667eea;padding-left:.6rem;background:linear-gradient(90deg,#f0f3fa,#ffffff);} 
    .mdt-md h3 {font-size:1.25rem;}
    .mdt-md h4 {font-size:1.05rem;color:#374151;}
    .mdt-md p {margin:0 0 1em;}
    .mdt-md ul, .mdt-md ol {margin:0 0 1.1em 1.4em;padding:0;}
    .mdt-md li {margin:.3em 0;}
    .mdt-md code {background:#f3f4f7;padding:2px 5px;border-radius:4px;font-size:90%;}
    .mdt-md pre {background:#1e293b;color:#e2e8f0;padding:14px 16px;border-radius:10px;overflow:auto;font-size:13px;line-height:1.5;}
    .mdt-md table {border-collapse:collapse;width:100%;margin:1.2em 0;}
    .mdt-md th, .mdt-md td {border:1px solid #dfe3eb;padding:8px 10px;font-size:13px;}
    .mdt-md th {background:#f1f4fa;font-weight:600;}
    .mdt-md blockquote {margin:1em 0;padding:12px 18px;border-left:6px solid #667eea;background:#f5f7fc;border-radius:8px;color:#394b63;}
    .mdt-md hr {border:none;border-top:1px solid #e1e5ec;margin:2rem 0;}
    .mdt-md strong {color:#1f2d3d;}
    .mdt-md .callout-title {display:inline-block;background:#667eea;color:#fff;padding:2px 10px;border-radius:6px;margin-right:8px;font-size:12px;letter-spacing:.5px;}
    .mdt-md .emphasis {background:linear-gradient(90deg,#fff6e5,#fff);padding:6px 10px;border-left:4px solid #ffb347;border-radius:6px;}
    .mdt-md a {color:#2563eb;text-decoration:none;}
    .mdt-md a:hover {text-decoration:underline;}
    .mdt-md .section-anchor {position:absolute;left:-12px;opacity:0;transition:.2s;font-size:14px;}
    .mdt-md h2:hover .section-anchor, .mdt-md h3:hover .section-anchor {opacity:.55;}

    /* ä¸‹è½½æŠ¥å‘Šé¢„è§ˆ */
    .report-preview {background:#ffffff;border:1px solid #e2e6ef;border-radius:16px;padding:28px 32px;margin:20px 0;box-shadow:0 6px 18px -4px rgba(0,0,0,0.08);}    

    /* ===== åŠ¨æ€æµç¨‹å›¾ï¼ˆæ°´å¹³æ­¥éª¤æµï¼‰ ===== */
    .mdt-flow-wrapper {background:linear-gradient(145deg,#ffffff,#f5f7fb);border:1px solid #e1e5ec;border-radius:18px;padding:20px 28px;margin:18px 0 30px 0;box-shadow:0 6px 22px -6px rgba(0,0,0,0.08);}
    .mdt-flow-steps {display:flex;flex-wrap:wrap;gap:12px 32px;align-items:flex-start;}
    .mdt-flow-step {position:relative;padding:10px 14px 10px 52px;min-width:180px;background:#ffffff;border:1px solid #dde2eb;border-radius:14px;box-shadow:0 4px 12px -4px rgba(0,0,0,.06);transition:.25s;}
    .mdt-flow-step:hover {box-shadow:0 8px 20px -6px rgba(0,0,0,.12);}    
    .mdt-flow-step.pending {opacity:.55;}
    .mdt-flow-step.current {border-color:#667eea;box-shadow:0 6px 18px -4px rgba(102,126,234,.45);} 
    .mdt-flow-step.done {background:linear-gradient(145deg,#eef7ff,#ffffff);border-color:#6abf69;}
    .mdt-flow-circle {position:absolute;left:14px;top:50%;transform:translateY(-50%);width:28px;height:28px;border-radius:50%;display:flex;align-items:center;justify-content:center;font-size:14px;font-weight:600;color:#fff;box-shadow:0 2px 6px rgba(0,0,0,.25);}    
    .mdt-flow-circle.pending {background:#b0b8c6;}
    .mdt-flow-circle.current {background:linear-gradient(135deg,#667eea,#764ba2);} 
    .mdt-flow-circle.done {background:#2ecc71;}
    .mdt-flow-title {margin:0 0 4px 0;font-size:14px;font-weight:600;color:#2d3748;}
    .mdt-flow-desc {margin:0;font-size:11px;line-height:1.3;color:#5a6475;}
    .mdt-flow-metrics {display:flex;gap:6px;margin-top:6px;flex-wrap:wrap;}
    .mdt-flow-badge {background:#eef1f7;padding:3px 8px;border-radius:12px;font-size:10px;font-weight:600;color:#445268;}
    .mdt-flow-rounds {margin-top:6px;font-size:11px;color:#37486b;font-weight:600;}
    .mdt-flow-active-agents {margin-top:4px;font-size:10px;color:#5b6472;}
    .mdt-flow-divider {height:1px;background:linear-gradient(90deg,transparent,#c8d2e2,transparent);margin:12px 0;}
</style>
""", unsafe_allow_html=True)

# ä¸“å®¶é…è‰²æ–¹æ¡ˆ
EXPERT_COLORS = {
    "å‘¼å¸ç§‘ä¸“å®¶": "#667eea",
    "å½±åƒç§‘ä¸“å®¶": "#f093fb", 
    "ç—…ç†ç§‘ä¸“å®¶": "#4facfe",
    "é£æ¹¿å…ç–«ç§‘ä¸“å®¶": "#43e97b",
    "æ•°æ®åˆ†æä¸“å®¶": "#fa709a",
    "MDTåè°ƒå‘˜": "#a8edea"
}

# å…¨å±€ä¸“å®¶åç§°æ˜ å°„ï¼ˆç»Ÿä¸€åˆ«ååŒ¹é…ï¼Œé¿å…å„å‡½æ•°é‡å¤å®šä¹‰ï¼‰
EXPERT_NAME_MAPPING = {
    "å‘¼å¸ç§‘ä¸“å®¶": ["pulmonary", "respiratory", "å‘¼å¸ç§‘", "å‘¼å¸ç§‘åŒ»ç”Ÿ"],
    "å½±åƒç§‘ä¸“å®¶": ["imaging", "radiology", "å½±åƒç§‘", "å½±åƒç§‘åŒ»ç”Ÿ"],
    "ç—…ç†ç§‘ä¸“å®¶": ["pathology", "ç—…ç†ç§‘", "ç—…ç†ç§‘åŒ»ç”Ÿ"],
    "é£æ¹¿å…ç–«ç§‘ä¸“å®¶": ["rheumatology", "é£æ¹¿å…ç–«ç§‘", "é£æ¹¿å…ç–«ç§‘åŒ»ç”Ÿ"],
    "æ•°æ®åˆ†æä¸“å®¶": ["data_analysis", "æ•°æ®åˆ†æ", "æ•°æ®åˆ†æä¸“å®¶"],
    # åè°ƒå‘˜ä¸å‚ä¸è¿‡æ»¤é€»è¾‘ï¼Œä»…åœ¨æœ€ç»ˆé˜¶æ®µæ˜¾ç¤º
    "MDTåè°ƒå‘˜": ["coordinator", "åè°ƒå‘˜", "mdtåè°ƒå‘˜"]
}

def get_expert_color(expert_name: str) -> str:
    """è·å–ä¸“å®¶å¯¹åº”çš„é¢œè‰²"""
    for key, color in EXPERT_COLORS.items():
        if key in expert_name:
            return color
    return "#6c757d"  # é»˜è®¤é¢œè‰²

def is_expert_selected(expert_name: str, selected_experts: List[str]) -> bool:
    """æ£€æŸ¥ä¸“å®¶æ˜¯å¦è¢«é€‰ä¸­"""
    # åè°ƒå‘˜ï¼ˆMDTåè°ƒå‘˜ï¼‰åº”å§‹ç»ˆæ˜¾ç¤ºï¼ˆå†²çªæ£€æµ‹ / å…±è¯†è¯„ä¼° / æœ€ç»ˆåè°ƒé˜¶æ®µéœ€è¦å®ƒçš„è¾“å‡ºï¼‰
    if any(key.lower() in expert_name.lower() for key in ["åè°ƒå‘˜", "mdtåè°ƒå‘˜", "coordinator"]):
        return True
    for selected in selected_experts:
        # ç›´æ¥åç§°åŒ…å«åŒ¹é…
        if selected in expert_name or expert_name in selected:
            return True
        # åˆ«ååŒ¹é…
        for alias in EXPERT_NAME_MAPPING.get(selected, []):
            if alias.lower() in expert_name.lower():
                return True
    return False

def display_expert_response(container, expert_name: str, full_text: str, status: str = "typing"):
    """æ˜¾ç¤ºä¸“å®¶å›å¤å†…å®¹"""
    color = get_expert_color(expert_name)
    
    # çŠ¶æ€æ ·å¼
    status_class = f"status-{status}"
    status_text = {
        "thinking": "æ€è€ƒä¸­...",
        "typing": "å›å¤ä¸­...", 
        "complete": "å®Œæˆ"
    }.get(status, "å¤„ç†ä¸­...")
    
    # ä½¿ç”¨ render_markdown_content å¤„ç†æ–‡æœ¬å†…å®¹
    if full_text.strip():
        rendered_content = render_markdown_content(full_text)
        # ç§»é™¤å¤–å±‚ div æ ·å¼ï¼Œåªä¿ç•™å†…éƒ¨ HTML
        import re
        # æå– div å†…çš„å†…å®¹
        content_match = re.search(r'<div[^>]*>(.*)</div>', rendered_content, re.DOTALL)
        if content_match:
            processed_text = content_match.group(1)
        else:
            processed_text = full_text
    else:
        processed_text = full_text
    
    # æ„å»ºå®Œæ•´çš„HTML
    html_content = f"""
    <div class="stream-card">
        <div class="expert-header">
            <div class="expert-avatar" style="background: {color};">
                {expert_name[0]}
            </div>
            <div class="expert-info">
                <h3>{expert_name}</h3>
                <p>{expert_name.replace('ä¸“å®¶', '').replace('MDT', 'å¤šå­¦ç§‘')}</p>
            </div>
        </div>
        <div class="status-indicator {status_class}">{status_text}</div>
        <div class="stream-content">
            <div class="stream-text">{processed_text}{'<span class="typing-indicator">â—</span>' if status == 'typing' else ''}</div>
        </div>
    </div>
    """
    
    container.markdown(html_content, unsafe_allow_html=True)

def render_phase_header(phase_name: str, description: str):
    """æ¸²æŸ“é˜¶æ®µæ ‡é¢˜"""
    st.markdown(f"""
    <div class="phase-progress">
        <h3>ğŸ”„ {phase_name}</h3>
        <p>{description}</p>
    </div>
    """, unsafe_allow_html=True)

def render_markdown_content(content: str) -> str:
    """
    ä½¿ç”¨ Python markdown åŒ…æ¸²æŸ“ Markdown å†…å®¹
    æ”¯æŒæ›´å¥½çš„æ ¼å¼åŒ–å’Œæ‰©å±•åŠŸèƒ½
    """
    if not content:
        return ""
    
    # æ¸…ç†å†…å®¹ï¼šç§»é™¤è¿‡å¤šçš„ç©ºè¡Œ
    cleaned_content = re.sub(r"\n{3,}", "\n\n", content.strip())
    
    try:
        # ä½¿ç”¨ markdown åŒ…è½¬æ¢ï¼Œåªä½¿ç”¨å…¼å®¹çš„æ‰©å±•
        md = markdown.Markdown(extensions=[
            'extra',          # æ”¯æŒè¡¨æ ¼ã€ä»£ç å—ç­‰
            'nl2br'          # æ¢è¡Œè½¬æ¢ä¸º <br>
        ])
        
        # è½¬æ¢ä¸º HTML
        html_content = md.convert(cleaned_content)
        
        # ç®€åŒ–çš„æ ·å¼å¤„ç†ï¼Œé¿å…ä¸ Streamlit å†²çª
        # ä¸º h2/h3 æ·»åŠ é”šç‚¹ç¬¦å·
        import re as _re
        def _add_anchor(match):
            tag = match.group(1)
            title = match.group(2)
            anchor_id = _re.sub(r'[^a-zA-Z0-9\u4e00-\u9fa5]+', '-', title).strip('-').lower()
            return f'<{tag} id="{anchor_id}"><span class="section-anchor">#</span>{title}</{tag}>'
        html_content = _re.sub(r'<(h[23])>(.*?)</h[23]>', _add_anchor, html_content)

        styled_content = f"""
        <div class="mdt-md">
            {html_content}
        </div>
        """
        
        return styled_content
        
    except Exception as e:
        # å¦‚æœ markdown å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•çš„æ–‡æœ¬å¤„ç†
        logger.warning(f"Markdown rendering failed: {e}")
        # ç®€å•çš„æ–‡æœ¬å¤„ç†ï¼šä¿ç•™æ¢è¡Œå’ŒåŸºæœ¬æ ¼å¼
        escaped_content = html.escape(cleaned_content)
        formatted_content = escaped_content.replace('\n', '<br>')
        
    return f"""
    <div class=\"mdt-md\">{formatted_content}</div>
    """

def display_case_summary():
    """æ˜¾ç¤ºç—…ä¾‹æ‘˜è¦ä¿¡æ¯ï¼ˆåªè¯»æ¨¡å¼ï¼‰"""
    case_data = st.session_state.get("case_data", {})
    
    if not case_data:
        st.warning("æœªæ‰¾åˆ°ç—…ä¾‹ä¿¡æ¯")
        return
    
    st.header("ğŸ“‹ å½“å‰ç—…ä¾‹ä¿¡æ¯")
    
    # ç¬¬ä¸€è¡Œ
    col1_1, col1_2, col1_3 = st.columns(3)
    
    with col1_1:
        st.markdown(f"**æ‚£è€…ID:** {case_data.get('patient_id', 'N/A')}")
    
    with col1_2:
        st.markdown("**ä¸»è¦ç—‡çŠ¶:**")
        st.text(case_data.get('chief_complaint', ''))
    
    with col1_3:
        st.markdown("**æ—¢å¾€å²:**")
        st.text(case_data.get('medical_history', ''))
    
    # ç¬¬äºŒè¡Œ
    col2_1, col2_2, col2_3 = st.columns(3)
    
    with col2_1:
        st.markdown("**ç°ç—…å²:**")
        st.text(case_data.get('present_illness', ''))
    
    with col2_2:
        st.markdown("**æ£€æŸ¥ç»“æœ:**")
        st.text(case_data.get('examination_results', ''))
    
    with col2_3:
        st.markdown("**ä½“æ ¼æ£€æŸ¥:**")
        st.text(case_data.get('physical_examination', ''))
    
    # ç¬¬ä¸‰è¡Œ
    col3_1, col3_2, col3_3 = st.columns(3)
    
    with col3_1:
        st.markdown("**å®éªŒå®¤æ£€æŸ¥:**")
        st.text(case_data.get('lab_results', ''))
    
    with col3_2:
        st.markdown("**ç”Ÿç‰©æ ‡å¿—ç‰©:**")
        st.text(case_data.get('biomarker_results', ''))
    
    with col3_3:
        st.markdown("**è‚ºåŠŸèƒ½æ£€æŸ¥:**")
        st.text(case_data.get('pulmonary_function_tests', ''))

def main():
    """ä¸»åº”ç”¨ç¨‹åº"""
    # ä½¿ç”¨æ–°çš„æ ·å¼æ ‡é¢˜
    st.markdown('<h1 class="main-title">ğŸ¥ é—´è´¨ç—…MDTæ™ºèƒ½è¯Šç–—ç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    st.markdown("**ä¸“ä¸šçš„å¤šå­¦ç§‘å›¢é˜Ÿè®¨è®ºå¹³å° - ä¸ºé—´è´¨æ€§è‚ºç—…è¯Šç–—æä¾›æ™ºèƒ½åŒ–æ”¯æŒ**")
    
    # åˆ†å‰²çº¿
    st.markdown('<div class="section-divider"></div>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("ğŸ“‹ ç³»ç»Ÿé…ç½®")

        # ä¸“å®¶é€‰æ‹©
        st.subheader("ğŸ‘¥ å‚ä¸ä¸“å®¶")
        available_experts = [
            "å‘¼å¸ç§‘ä¸“å®¶", "å½±åƒç§‘ä¸“å®¶", "ç—…ç†ç§‘ä¸“å®¶",
            "é£æ¹¿å…ç–«ç§‘ä¸“å®¶", "æ•°æ®åˆ†æä¸“å®¶"
        ]
        selected_experts = st.multiselect(
            "é€‰æ‹©å‚ä¸è®¨è®ºçš„ä¸“å®¶",
            available_experts,
            default=available_experts
        )

        if st.button(
            "ğŸš€ å¼€å§‹MDTè®¨è®º",
            type="primary",
            use_container_width=True
        ):
            st.session_state.start_stream = True
            st.session_state.stream_complete = False
            st.session_state.current_phase = None
            st.session_state.expert_containers = {}

        st.markdown("---")
        # çŸ¥è¯†åº“ / RAG ç®¡ç†é¢æ¿
        st.subheader("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
        
        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        stats = knowledge_store.get_collection_stats()
        backend = stats.get('backend','N/A')
        total_docs = stats.get('total_documents', 0)
        st.caption(f"Backend: {backend} | å‘é‡ç‰‡æ®µ: {total_docs} | çŠ¶æ€: {stats.get('status')}")
        
        # æ˜¾ç¤ºå½“å‰çŸ¥è¯†åº“ä¸­çš„æ–‡ä»¶åˆ—è¡¨
        with st.expander("ğŸ“‹ å·²åŠ è½½æ–‡ä»¶åˆ—è¡¨", expanded=False):
            docs_dir = os.path.join(project_root, 'knowledge', 'documents')
            if os.path.isdir(docs_dir):
                files = []
                for ext in ['*.txt', '*.md', '*.pdf', '*.csv']:
                    files.extend(glob.glob(os.path.join(docs_dir, ext)))
                
                if files:
                    st.write(f"ğŸ“ æ–‡ä»¶ç›®å½•: `{docs_dir}`")
                    for i, file_path in enumerate(sorted(files), 1):
                        file_name = os.path.basename(file_path)
                        file_size = os.path.getsize(file_path)
                        size_kb = file_size / 1024
                        file_ext = os.path.splitext(file_name)[1].upper()
                        st.write(f"{i}. **{file_name}** ({file_ext}, {size_kb:.1f}KB)")
                else:
                    st.info("ğŸ“­ documents æ–‡ä»¶å¤¹ä¸ºç©º")
            else:
                st.warning("ğŸ“ documents ç›®å½•ä¸å­˜åœ¨")
        
        # æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½
        st.markdown("#### ğŸ“¤ ä¸Šä¼ æ–°æ–‡ä»¶")
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶ä¸Šä¼ åˆ°çŸ¥è¯†åº“", 
            type=["txt", "md", "pdf", "csv"], 
            accept_multiple_files=True,
            help="æ”¯æŒ TXT, MD, PDF, CSV æ ¼å¼ï¼Œä¸Šä¼ åå°†ä¿å­˜åˆ° knowledge/documents æ–‡ä»¶å¤¹"
        )
        
        if uploaded_files:
            docs_dir = os.path.join(project_root, 'knowledge', 'documents')
            os.makedirs(docs_dir, exist_ok=True)
            
            saved_files = []
            for uploaded_file in uploaded_files:
                # ä¿å­˜æ–‡ä»¶åˆ° documents ç›®å½•
                file_path = os.path.join(docs_dir, uploaded_file.name)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                if os.path.exists(file_path):
                    st.warning(f"âš ï¸ æ–‡ä»¶ {uploaded_file.name} å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–")
                
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                saved_files.append(uploaded_file.name)
            
            if saved_files:
                st.success(f"âœ… å·²ä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶åˆ° documents æ–‡ä»¶å¤¹")
                for fname in saved_files:
                    st.write(f"   ğŸ“„ {fname}")
                st.info("ğŸ’¡ ç‚¹å‡»ä¸‹æ–¹ã€Œå¢é‡æ›´æ–°ã€æŒ‰é’®å°†æ–°æ–‡ä»¶æ·»åŠ åˆ°å‘é‡åº“")
        
        # çŸ¥è¯†åº“æ“ä½œæŒ‰é’®
        st.markdown("#### ğŸ”§ çŸ¥è¯†åº“æ“ä½œ")
        col_kb1, col_kb2, col_kb3 = st.columns(3)
        
        with col_kb1:
            if st.button('ğŸ”„ å®Œå…¨é‡å»º', help='æ¸…ç©ºç°æœ‰å‘é‡åº“ï¼Œé‡æ–°å¤„ç†æ‰€æœ‰æ–‡ä»¶'):
                with st.spinner('æ­£åœ¨é‡å»ºçŸ¥è¯†åº“...'):
                    docs_dir = os.path.join(project_root, 'knowledge', 'documents')
                    if knowledge_store.clear_collection() and os.path.isdir(docs_dir):
                        summary = knowledge_store.rebuild_from_directory(
                            docs_dir, 
                            patterns=['*.txt','*.md'], 
                            include_pdf=True, 
                            include_csv=True
                        )
                        st.success(f"ğŸ‰ é‡å»ºå®Œæˆï¼\nğŸ“Š chunks={summary['chunks_added']} | txt={summary['txt_files']} | pdf={summary['pdf_files']} | csv={summary['csv_files']}")
                        if summary.get('errors'):
                            st.error(f"âš ï¸ å¤„ç†é”™è¯¯: {len(summary['errors'])} ä¸ª")
                    else:
                        st.warning('ç›®å½•ä¸å­˜åœ¨æˆ–æ¸…ç©ºå¤±è´¥')
        
        with col_kb2:
            if st.button('â• å¢é‡æ›´æ–°', help='ä»…å¤„ç†æ–°æ–‡ä»¶ï¼Œæ·»åŠ åˆ°ç°æœ‰å‘é‡åº“'):
                with st.spinner('æ­£åœ¨å¢é‡æ›´æ–°...'):
                    docs_dir = os.path.join(project_root, 'knowledge', 'documents')
                    if os.path.isdir(docs_dir):
                        summary = knowledge_store.add_new_files_only(
                            docs_dir, 
                            patterns=['*.txt','*.md'], 
                            include_pdf=True, 
                            include_csv=True
                        )
                        if summary['files_processed'] > 0:
                            st.success(f"ğŸ“ˆ å¢é‡æ›´æ–°å®Œæˆï¼\næ–°å¤„ç†æ–‡ä»¶: {summary['files_processed']} | æ–°å¢chunks: {summary['chunks_added']} | è·³è¿‡å·²å¤„ç†: {summary['skipped_files']}")
                        else:
                            st.info("ğŸ’¡ æ²¡æœ‰å‘ç°æ–°æ–‡ä»¶ï¼ŒçŸ¥è¯†åº“ä¿æŒä¸å˜")
                        if summary.get('errors'):
                            st.error(f"âš ï¸ å¤„ç†é”™è¯¯: {len(summary['errors'])} ä¸ª")
                    else:
                        st.warning('documents ç›®å½•ä¸å­˜åœ¨')
        
        with col_kb3:
            if st.button('ğŸ§¹ æ¸…ç©º', help='åˆ é™¤æ‰€æœ‰å‘é‡æ•°æ®'):
                if st.session_state.get('confirm_clear'):
                    if knowledge_store.clear_collection():
                        st.success('âœ… å·²æ¸…ç©ºçŸ¥è¯†åº“')
                        st.session_state.confirm_clear = False
                else:
                    st.session_state.confirm_clear = True
                    st.warning('âš ï¸ ç¡®è®¤æ¸…ç©ºï¼Ÿè¯·å†æ¬¡ç‚¹å‡»ç¡®è®¤')
        
        # æ£€ç´¢æµ‹è¯•
        with st.expander('ğŸ” æ£€ç´¢æµ‹è¯•', expanded=False):
            test_query = st.text_input('æµ‹è¯•æŸ¥è¯¢', placeholder='è¾“å…¥å…³é”®è¯æµ‹è¯•æ£€ç´¢æ•ˆæœ')
            test_specialty = st.selectbox('ä¸“ç§‘ä¸Šä¸‹æ–‡', ['(è‡ªåŠ¨)','pulmonary','imaging','pathology','rheumatology','data_analysis','coordinator'])
            col_test1, col_test2 = st.columns(2)
            with col_test1:
                multi_flag = st.checkbox('Multi-Query', value=False)
                topk = st.slider('è¿”å›æ•°é‡', 1, 10, 5)
            with col_test2:
                if st.button('ğŸ” æ‰§è¡Œæ£€ç´¢', disabled=not test_query.strip()):
                    spec = '' if test_specialty == '(è‡ªåŠ¨)' else (test_specialty or '')
                    if multi_flag:
                        case_info = {'symptoms': test_query.strip(), 'medical_history': ''}
                        context_preview = knowledge_store.multi_query_context(case_info, spec or 'pulmonary', n_queries=4, per_query_k=topk)
                        st.code(context_preview[:1500] or 'æ— ç»“æœ', language='markdown')
                    else:
                        results = knowledge_store.search_relevant_knowledge(test_query.strip(), spec, k=topk)
                        if not results:
                            st.info('ğŸ“­ æ— æ£€ç´¢ç»“æœ')
                        else:
                            for i, r in enumerate(results, 1):
                                st.markdown(f"**#{i}** (ç›¸å…³åº¦: {r.get('relevance_score'):.3f}) | æ¥æº: `{r.get('source','æœªçŸ¥')}`")
                                st.code(r.get('content','')[:400], language='text')
        st.markdown("---")
        st.subheader("ğŸ§© Prompt ç®¡ç†")
        if st.button("â™»ï¸ çƒ­åŠ è½½å…¨éƒ¨", use_container_width=True):
            _reload_all_prompts()
            st.success("Prompt å·²çƒ­åŠ è½½")
        # å‹å¥½æ ‡ç­¾ & åˆ†ç±»è¿‡æ»¤
        col_pf, col_cat = st.columns([2,1])
        with col_pf:
            prompt_filter = st.text_input("æŒ‰ ID è¿‡æ»¤ (å‰ç¼€)", "")
        with col_cat:
            cat_filter = st.selectbox(
                "åˆ†ç±»è¿‡æ»¤",
                options=["(å…¨éƒ¨)", "ç³»ç»Ÿæç¤º", "ä¸»åˆ†æ", "åè°ƒæµç¨‹", "ç—…ç†å­ä»»åŠ¡", "é£æ¹¿å­ä»»åŠ¡", "æ•°æ®å­ä»»åŠ¡", "é€šç”¨ä»»åŠ¡", "æ¸…å•"],
                index=0
            )
        try:
            _all_prompts = _list_prompts()
            # è¯»å–å…¨éƒ¨å…ƒæ•°æ®å¹¶æŒ‰ group èšåˆ
            from prompts.loader import get_prompt_meta as __pm
            group_map: dict[str, list[str]] = {}
            for pid in _all_prompts.keys():
                meta = __pm(pid) or {}
                g = meta.get('group', 'æœªåˆ†ç»„') or 'æœªåˆ†ç»„'
                group_map.setdefault(g, []).append(pid)
            keys_raw = sorted(_all_prompts.keys())
            def _visible(pid: str) -> bool:
                if prompt_filter and not pid.startswith(prompt_filter.upper()):
                    return False
                if cat_filter and cat_filter != "(å…¨éƒ¨)":
                    meta = _get_prompt_meta(pid)
                    if not meta or meta.get('category') != cat_filter:
                        return False
                return True
            keys = [k for k in keys_raw if _visible(k)]
            # æ ‘å½¢åˆ†ç»„å±•ç¤º
            with st.expander("æŒ‰æ™ºèƒ½ä½“åˆ†ç»„æµè§ˆ (Group â†’ Prompts)", expanded=False):
                for g_name in sorted(group_map.keys()):
                    with st.container():
                        st.markdown(f"**ğŸ“‚ {g_name}**")
                        sub_cols = st.columns(2)
                        col_idx = 0
                        for pid in sorted(group_map[g_name]):
                            if pid not in keys:  # è¿‡æ»¤åä¸å¯è§
                                continue
                            meta = _get_prompt_meta(pid) or {}
                            label = meta.get('label', pid)
                            short_desc = meta.get('description', '')[:40]
                            with sub_cols[col_idx % 2]:
                                if st.button(f"{label}\n{pid}", key=f"btn_{pid}", help=short_desc):
                                    st.session_state['__prompt_selected_pid'] = pid
                            col_idx += 1
                        st.markdown("---")
            # å›é€€ï¼šä¸‹æ‹‰å¿«é€Ÿå®šä½ + ä¸æŒ‰é’®äº’é€š
            display_options = ["(é€‰æ‹©ä»¥é¢„è§ˆ)"]
            id_map: dict[str, str | None] = {"(é€‰æ‹©ä»¥é¢„è§ˆ)": None}
            for pid in keys:
                meta = _get_prompt_meta(pid) or {}
                label = meta.get('label', pid)
                display_text = f"{label} Â· {pid}"
                display_options.append(display_text)
                id_map[display_text] = pid
            selected_display = st.selectbox("å¿«é€Ÿé€‰æ‹©", options=display_options, key="select_prompt_dropdown")
            selected_pid = (id_map.get(selected_display) if selected_display else None) or st.session_state.get('__prompt_selected_pid')
            if selected_pid:
                raw_text = _get_prompt(selected_pid)
                meta = _get_prompt_meta(selected_pid) or {}
                st.caption(f"æ–‡ä»¶: {_all_prompts[selected_pid]}")
                st.markdown(f"**åç§°:** {meta.get('label', selected_pid)}  ")
                if meta.get('description'):
                    st.markdown(f"**è¯´æ˜:** {meta['description']}")
                badge_cols = st.columns(3)
                with badge_cols[0]:
                    st.metric("åˆ†ç±»", meta.get('category', 'â€”'))
                with badge_cols[1]:
                    st.metric("è§’è‰²", meta.get('role', 'â€”'))
                with badge_cols[2]:
                    st.metric("ID", selected_pid)
                with st.expander("æŸ¥çœ‹åŸå§‹Markdown", expanded=False):
                    st.code(raw_text[:4000], language="markdown")
                # å ä½ç¬¦æ£€æµ‹
                import re as _re
                ph = sorted(set(_re.findall(r"\{([a-zA-Z_][a-zA-Z0-9_]*)\}", raw_text)))
                if ph:
                    st.write("å ä½ç¬¦:", ", ".join(ph))
                # æ¼”ç¤ºå®‰å…¨æ ¼å¼åŒ–
                if st.checkbox("âš™ï¸ æ¼”ç¤º safe_format", key=f"sf_{selected_pid}"):
                    demo_json = st.text_area("æä¾› JSON æ ¼å¼æ•°æ® (å¯ç¼ºå¤±)", value="{}", height=120)
                    try:
                        import json as _json
                        data_obj = _json.loads(demo_json or '{}')
                        formatted, missing = _safe_format(raw_text, **data_obj)
                        st.markdown("**æ ¼å¼åŒ–ç»“æœ (æˆªæ–­å‰ 800 å­—):**")
                        st.code(formatted[:800], language="markdown")
                        if missing:
                            st.warning("ç¼ºå¤±å˜é‡: " + ", ".join(missing))
                        else:
                            st.success("æ— ç¼ºå¤±å˜é‡")
                    except Exception as _e:
                        st.error(f"è§£æ/æ ¼å¼åŒ–å¤±è´¥: {_e}")
        except Exception as _e:
            st.warning(f"åŠ è½½ Prompt åˆ—è¡¨å¤±è´¥: {_e}")
    
    # ç—…ä¾‹ä¿¡æ¯æ˜¾ç¤º/è¾“å…¥
    if not st.session_state.get("start_stream", False):
        st.header("ğŸ“ ç—…ä¾‹ä¿¡æ¯å½•å…¥")
        
        # æ·»åŠ ç¤ºä¾‹ç—…ä¾‹é€‰æ‹©åŠŸèƒ½
        with st.expander("ğŸ“ ç¤ºä¾‹ç—…ä¾‹é€‰æ‹©", expanded=True):
            sample_cases = {
                "CTD-ILD": {
                    "file": "ctd_ild_case.json",
                    "description": "ç±»é£æ¹¿å…³èŠ‚ç‚ç›¸å…³é—´è´¨æ€§è‚ºç—…ï¼ŒUIPæ¨¡å¼"
                },
                "IPF": {
                    "file": "ipf_case.json", 
                    "description": "ç‰¹å‘æ€§è‚ºçº¤ç»´åŒ–ï¼Œå…¸å‹UIPæ¨¡å¼ï¼Œå¿«é€Ÿè¿›å±•"
                },
                "è¿‡æ•æ€§è‚ºç‚": {
                    "file": "hp_case.json",
                    "description": "æ…¢æ€§è¿‡æ•æ€§è‚ºç‚ï¼Œé¸½å­æš´éœ²ç›¸å…³"
                },
                "æœºåŒ–æ€§è‚ºç‚": {
                    "file": "op_case.json",
                    "description": "æœºåŒ–æ€§è‚ºç‚ï¼Œæ¿€ç´ æ•æ„Ÿå‹"
                },
                "è‚ºç™Œ": {
                    "file": "lung_cancer_case.json",
                    "description": "è‚ºè…ºç™Œï¼Œåˆ†æœŸå’Œæ²»ç–—å†³ç­–"
                },
                "ä¹³è…ºç™Œ": {
                    "file": "breast_cancer_case.json", 
                    "description": "ä¹³è…ºç™Œï¼Œå¤šå­¦ç§‘ç»¼åˆæ²»ç–—"
                }
            }
            
            col_select, col_load = st.columns([3, 1])
            
            with col_select:
                selected_case = st.selectbox(
                    "é€‰æ‹©ç¤ºä¾‹ç—…ä¾‹ç±»å‹",
                    options=list(sample_cases.keys()),
                    help="é€‰æ‹©ä¸åŒç±»å‹çš„ç—…ä¾‹è¿›è¡Œæµ‹è¯•"
                )
            
            with col_load:
                st.write("")  # æ·»åŠ ç©ºè¡Œå¯¹é½
                if st.button(f"ğŸ“ åŠ è½½", key="load_case"):
                    try:
                        if selected_case and selected_case in sample_cases:
                            case_file = sample_cases[selected_case]["file"]
                            case_path = os.path.join(project_root, "data", "sample_cases", case_file)
                            with open(case_path, 'r', encoding='utf-8') as f:
                                sample_case = json.load(f)
                            st.session_state.sample_case = sample_case
                            st.success(f"âœ… {selected_case}ç¤ºä¾‹ç—…ä¾‹å·²åŠ è½½")
                            st.info(f"ğŸ“ {sample_cases[selected_case]['description']}")
                            st.rerun()
                        else:
                            st.error("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªç—…ä¾‹")
                    except Exception as e:
                        st.error(f"åŠ è½½ç¤ºä¾‹ç—…ä¾‹å¤±è´¥: {e}")
            
            if selected_case and selected_case in sample_cases:
                st.markdown(f"**{selected_case}**: {sample_cases[selected_case]['description']}")
        
        # ç—…ä¾‹ä¿¡æ¯è¡¨å• - 3è¡Œ3åˆ—å¸ƒå±€
        # å¦‚æœæœ‰åŠ è½½çš„ç¤ºä¾‹ç—…ä¾‹ï¼Œä½¿ç”¨å…¶æ•°æ®ä½œä¸ºé»˜è®¤å€¼ï¼Œå¦åˆ™æ˜¾ç¤ºå¡«å†™è¯´æ˜
        sample_data = st.session_state.get('sample_case', {})
        has_loaded_case = bool(sample_data)
        
        # æ˜¾ç¤ºçŠ¶æ€æç¤º
        if not has_loaded_case:
            st.info("ğŸ’¡ **å¡«å†™æŒ‡å¯¼**ï¼šè¯·å¡«å†™æ‚£è€…çš„è¯¦ç»†ä¿¡æ¯ï¼Œæˆ–ä»ä¸Šæ–¹åŠ è½½ç¤ºä¾‹ç—…ä¾‹ã€‚æ‰€æœ‰å­—æ®µéƒ½æä¾›äº†è¯¦ç»†çš„å¡«å†™è¯´æ˜ã€‚")
        else:
            st.success("âœ… **å·²åŠ è½½ç—…ä¾‹æ•°æ®**ï¼šæ‚¨å¯ä»¥ä¿®æ”¹ä»¥ä¸‹ä¿¡æ¯æˆ–ç›´æ¥å¼€å§‹ MDT è®¨è®ºã€‚")
        
        # ç¬¬ä¸€è¡Œ
        col1_1, col1_2, col1_3 = st.columns(3)
        
        with col1_1:
            patient_id = st.text_input("æ‚£è€…ID", 
                value=sample_data.get("patient_id", ""),
                placeholder="è¯·è¾“å…¥æ‚£è€…å”¯ä¸€æ ‡è¯†ç ï¼Œå¦‚ï¼šILD_001" if not has_loaded_case else "")
        
        with col1_2:
            chief_complaint = st.text_area("ä¸»è¦ç—‡çŠ¶", 
                value=sample_data.get("chief_complaint", ""),
                placeholder="è¯·æè¿°æ‚£è€…ä¸»è¦ç—‡çŠ¶ï¼Œå¦‚ï¼š\nâ€¢ å‘¼å¸å›°éš¾çš„æ€§è´¨å’Œç¨‹åº¦\nâ€¢ å’³å—½ç‰¹ç‚¹ï¼ˆå¹²å’³/æœ‰ç—°ï¼‰\nâ€¢ ç—‡çŠ¶æŒç»­æ—¶é—´\nâ€¢ è¯±å‘æˆ–ç¼“è§£å› ç´ " if not has_loaded_case else "",
                height=100)
        
        with col1_3:
            medical_history = st.text_area("æ—¢å¾€å²", 
                value=sample_data.get("medical_history", ""),
                placeholder="è¯·è¯¦ç»†è®°å½•æ‚£è€…æ—¢å¾€ç—…å²ï¼Œå¦‚ï¼š\nâ€¢ è‡ªèº«å…ç–«æ€§ç–¾ç—…å²\nâ€¢ é•¿æœŸç”¨è¯å²\nâ€¢ èŒä¸šæš´éœ²å²\nâ€¢ å®¶æ—å²ç­‰" if not has_loaded_case else "",
                height=100)
        
        # ç¬¬äºŒè¡Œ
        col2_1, col2_2, col2_3 = st.columns(3)
        
        with col2_1:
            present_illness = st.text_area("ç°ç—…å²", 
                value=sample_data.get("symptoms", ""),
                placeholder="è¯·æè¿°ç°ç—…å²ï¼Œå¦‚ï¼š\nâ€¢ èµ·ç—…æ—¶é—´å’Œæ–¹å¼\nâ€¢ ç—‡çŠ¶æ¼”å˜è¿‡ç¨‹\nâ€¢ å°±è¯Šç»è¿‡\nâ€¢ æ²»ç–—æ•ˆæœç­‰" if not has_loaded_case else "",
                height=120)
        
        with col2_2:
            examination_results = st.text_area("æ£€æŸ¥ç»“æœ", 
                value=sample_data.get("imaging_results", ""),
                placeholder="è¯·å¡«å†™å½±åƒå­¦æ£€æŸ¥ç»“æœï¼Œå¦‚ï¼š\nâ€¢ HRCTè¡¨ç°\nâ€¢ Xçº¿èƒ¸ç‰‡\nâ€¢ å…¶ä»–å½±åƒå­¦æ£€æŸ¥\nâ€¢ å…¸å‹å¾è±¡æè¿°" if not has_loaded_case else "",
                height=120)
        
        with col2_3:
            physical_examination = st.text_area("ä½“æ ¼æ£€æŸ¥", 
                value=sample_data.get("physical_examination", ""),
                placeholder="è¯·è®°å½•ä½“æ ¼æ£€æŸ¥ç»“æœï¼Œå¦‚ï¼š\nâ€¢ èƒ¸éƒ¨å¬è¯Šæ‰€è§\nâ€¢ å‘¼å¸éŸ³ç‰¹ç‚¹\nâ€¢ å•°éŸ³åˆ†å¸ƒ\nâ€¢ å…¶ä»–é˜³æ€§ä½“å¾" if not has_loaded_case else "",
                height=120)
        
        # ç¬¬ä¸‰è¡Œ
        col3_1, col3_2, col3_3 = st.columns(3)
        
        with col3_1:
            lab_results = st.text_area("å®éªŒå®¤æ£€æŸ¥", 
                value=sample_data.get("lab_results", ""),
                placeholder="è¯·å¡«å†™å®éªŒå®¤æ£€æŸ¥ç»“æœï¼Œå¦‚ï¼š\nâ€¢ è¡€å¸¸è§„\nâ€¢ ç”ŸåŒ–æŒ‡æ ‡\nâ€¢ ç‚ç—‡æ ‡å¿—ç‰©\nâ€¢ å…ç–«æŒ‡æ ‡ç­‰" if not has_loaded_case else "",
                height=100)
        
        with col3_2:
            biomarker_results = st.text_area("ç”Ÿç‰©æ ‡å¿—ç‰©", 
                value=sample_data.get("biomarker_results", ""),
                placeholder="è¯·å¡«å†™ç”Ÿç‰©æ ‡å¿—ç‰©æ£€æµ‹ç»“æœï¼Œå¦‚ï¼š\nâ€¢ è‡ªèº«æŠ—ä½“\nâ€¢ ILDç›¸å…³æ ‡å¿—ç‰©\nâ€¢ KL-6ã€SP-Aã€SP-Dç­‰\nâ€¢ å…¶ä»–ç‰¹å¼‚æ€§æ ‡å¿—ç‰©" if not has_loaded_case else "",
                height=100)
        
        with col3_3:
            pulmonary_function_tests = st.text_area("è‚ºåŠŸèƒ½æ£€æŸ¥", 
                value=sample_data.get("pulmonary_function_tests", ""),
                placeholder="è¯·å¡«å†™è‚ºåŠŸèƒ½æ£€æŸ¥ç»“æœï¼Œå¦‚ï¼š\nâ€¢ FVCã€FEV1ç­‰æŒ‡æ ‡\nâ€¢ DLCOæ£€æµ‹ç»“æœ\nâ€¢ é€šæ°”åŠŸèƒ½è¯„ä¼°\nâ€¢ æ°”ä½“äº¤æ¢åŠŸèƒ½" if not has_loaded_case else "",
                height=100)
            
        # ä¿å­˜ç—…ä¾‹æ•°æ®åˆ°session stateï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰
        st.session_state.case_data = {
            "patient_id": patient_id,
            "chief_complaint": chief_complaint,
            "present_illness": present_illness,
            "medical_history": medical_history,
            "examination_results": examination_results,
            "physical_examination": physical_examination,
            "lab_results": lab_results,
            "biomarker_results": biomarker_results,
            "pulmonary_function_tests": pulmonary_function_tests,
            "timestamp": datetime.now().isoformat(),
            "full_case_data": sample_data  # ä¿å­˜å®Œæ•´çš„ç—…ä¾‹æ•°æ®
        }
    
    # åœ¨MDTè®¨è®ºæ—¶æ˜¾ç¤ºç—…ä¾‹ä¿¡æ¯å¹¶æ‰§è¡ŒMDT
    elif st.session_state.get("start_stream", False) and not st.session_state.get("stream_complete", False):
        display_case_summary()
        st.markdown("---")
        # æ‰§è¡ŒMDTè®¨è®º
        run_real_stream_mdt(selected_experts)
    
    # æ˜¾ç¤ºå®ŒæˆçŠ¶æ€
    elif st.session_state.get("stream_complete", False):
        display_case_summary()
        st.markdown("---")
        st.success("ğŸ‰ MDTè®¨è®ºå·²å®Œæˆï¼")
        
        # æ˜¾ç¤ºå®Œæ•´çš„MDTç»“æœï¼ˆå‚è€ƒåŸåº”ç”¨çš„æ˜¾ç¤ºé€»è¾‘ï¼‰
        if st.session_state.get("mdt_result"):
            display_mdt_results(st.session_state.mdt_result, st.session_state.get("case_data", {}))
        
        if st.button("ğŸ”„ å¼€å§‹æ–°çš„è®¨è®º"):
            # é‡ç½®çŠ¶æ€
            for key in ["start_stream", "stream_complete", "current_phase", "expert_containers", "mdt_result"]:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()

def display_mdt_results(result: Dict[str, Any], case_data: Dict[str, Any]):
    """æ˜¾ç¤ºå®Œæ•´çš„MDTç»“æœï¼ˆå‚è€ƒåŸåº”ç”¨çš„æ˜¾ç¤ºé€»è¾‘ï¼‰"""
    
    # è·å–å‚ä¸çš„ä¸“å®¶åˆ—è¡¨
    selected_experts = result.get("participants", [])
    
    # åŸºæœ¬ä¿¡æ¯
    st.subheader("ğŸ“„ ä¼šè®®åŸºæœ¬ä¿¡æ¯")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ä¼šè®®ID", result.get("session_id", "N/A"))
    with col2:
        st.metric("å‚ä¸ä¸“å®¶", len(selected_experts))
    with col3:
        st.metric("ä¼šè®®æ—¶é•¿", result.get("duration", "N/A"))
    
    # å„é˜¶æ®µç»“æœ
    st.subheader("ğŸ” å¤šè½®MDTè®¨è®ºç»“æœ")
    
    phases = result.get("phases", {})
    
    # ç¬¬1æ­¥ï¼šå„ä¸“ç§‘ç‹¬ç«‹åˆ†æ
    if "individual_analysis" in phases:
        display_individual_analysis(phases["individual_analysis"], selected_experts)
    
    # ç¬¬2æ­¥ï¼šä¸“ç§‘é—´åˆæ­¥è®¨è®º
    if "sharing_discussion" in phases:
        display_sharing_discussion(phases["sharing_discussion"], selected_experts)
    
    # ç¬¬3æ­¥ï¼šæ„è§å†²çªæ£€æµ‹
    if "conflict_detection" in phases:
        display_conflict_detection(phases["conflict_detection"])
    
    # ç¬¬4æ­¥ï¼šå¤šè½®è®¨è®ºé˜¶æ®µ
    if "multi_round_discussion" in phases:
        display_multi_round_discussion(phases["multi_round_discussion"], selected_experts)
    
    # ç¬¬5æ­¥ï¼šå…±è¯†è¯„ä¼°
    if "consensus_evaluation" in phases:
        display_consensus_evaluation(phases["consensus_evaluation"])
    
    # ç¬¬6æ­¥ï¼šæœ€ç»ˆåè°ƒå»ºè®®
    if "final_coordination" in phases:
        display_final_coordination(phases["final_coordination"])
    
    # ä¸‹è½½ç»“æœ
    display_download_section(result, case_data)

def display_individual_analysis(individual_data: Dict[str, Any], selected_experts: List[str]):
    """æ˜¾ç¤ºå„ä¸“ç§‘ç‹¬ç«‹åˆ†æ"""
    st.markdown("### ğŸ¥ å„ä¸“ç§‘ç‹¬ç«‹åˆ†æ")
    st.markdown("æ¯ä½ä¸“å®¶åŸºäºç—…ä¾‹ä¿¡æ¯è¿›è¡Œç‹¬ç«‹åˆ†æï¼Œç¡®ä¿è§‚ç‚¹çš„å®¢è§‚æ€§å’Œå¤šæ ·æ€§")
    
    # è¿‡æ»¤åªæ˜¾ç¤ºé€‰ä¸­çš„ä¸“å®¶
    filtered_data = {}
    for key, value in individual_data.items():
        expert_found = False
        for expert_name in selected_experts:
            possible_keys = EXPERT_NAME_MAPPING.get(expert_name, [expert_name])
            if key in possible_keys or expert_name in key:
                filtered_data[key] = value
                expert_found = True
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œæ£€æŸ¥ agent å­—æ®µ
        if not expert_found and isinstance(value, dict):
            agent_name = value.get('agent', '')
            for expert_name in selected_experts:
                if expert_name in agent_name or any(keyword in agent_name for keyword in EXPERT_NAME_MAPPING.get(expert_name, [])):
                    filtered_data[key] = value
                    break
    
    agent_list = list(filtered_data.items())

    # å“åº”å¼å¸ƒå±€ï¼šæ¯è¡Œ2-3ä¸ªå¡ç‰‡ï¼ˆä¿æŠ¤ç©ºæ•°æ®ï¼‰
    num_agents = len(agent_list)
    if num_agents == 0:
        st.info("æš‚æ— å¯æ˜¾ç¤ºçš„ä¸“å®¶ç‹¬ç«‹åˆ†æã€‚")
        st.markdown("---")
        return
    cols_per_row = min(3, num_agents)

    # åˆ†æ‰¹æ˜¾ç¤ºå¡ç‰‡
    for i in range(0, num_agents, cols_per_row):
        batch = agent_list[i:i + cols_per_row]
        cols = st.columns(len(batch))
        
        for j, (agent_name, response) in enumerate(batch):
            with cols[j]:
                display_expert_card(response, i + j, "individual")
    
    st.markdown("---")

def display_sharing_discussion(sharing_data: Dict[str, Any], selected_experts: List[str]):
    """æ˜¾ç¤ºä¸“ç§‘é—´åˆæ­¥è®¨è®º"""
    st.markdown("### ğŸ”„ ä¸“ç§‘é—´åˆæ­¥è®¨è®º")
    st.markdown("ä¸“å®¶ä»¬æŸ¥çœ‹å½¼æ­¤çš„æ„è§åè¿›è¡Œåˆæ­¥äº¤æµå’Œè¡¥å……")
    
    # è¿‡æ»¤åªæ˜¾ç¤ºé€‰ä¸­çš„ä¸“å®¶
    filtered_data = {}
    for key, value in sharing_data.items():
        expert_found = False
        for expert_name in selected_experts:
            possible_keys = EXPERT_NAME_MAPPING.get(expert_name, [expert_name])
            if key in possible_keys or expert_name in key:
                filtered_data[key] = value
                expert_found = True
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œæ£€æŸ¥ agent å­—æ®µ
        if not expert_found and isinstance(value, dict):
            agent_name = value.get('agent', '')
            for expert_name in selected_experts:
                if expert_name in agent_name or any(keyword in agent_name for keyword in EXPERT_NAME_MAPPING.get(expert_name, [])):
                    filtered_data[key] = value
                    break
    
    agent_list = list(filtered_data.items())

    # å“åº”å¼å¸ƒå±€ï¼ˆä¿æŠ¤ç©ºæ•°æ®ï¼‰
    num_agents = len(agent_list)
    if num_agents == 0:
        st.info("æš‚æ— å¯æ˜¾ç¤ºçš„ä¸“ç§‘é—´è®¨è®ºå†…å®¹ã€‚")
        st.markdown("---")
        return
    cols_per_row = min(3, num_agents)

    # åˆ†æ‰¹æ˜¾ç¤ºå¡ç‰‡
    for i in range(0, num_agents, cols_per_row):
        batch = agent_list[i:i + cols_per_row]
        cols = st.columns(len(batch))
        
        for j, (agent_name, response) in enumerate(batch):
            with cols[j]:
                display_expert_card(response, i + j, "sharing")
    
    st.markdown("---")

def display_conflict_detection(conflict_data: Dict[str, Any]):
    """æ˜¾ç¤ºæ„è§å†²çªæ£€æµ‹ (å…¨å®½ä¸“ä¸šå¡ç‰‡æ ·å¼)"""
    st.markdown("""
    <div class="phase-wide-card">
        <h3 class="section-title">âš”ï¸ æ„è§å†²çªæ£€æµ‹</h3>
        <p class="sub-note">æ™ºèƒ½åˆ†æå„ä¸“å®¶æ„è§ä¸­çš„åˆ†æ­§ç‚¹ï¼Œå†³å®šæ˜¯å¦éœ€è¦æ·±å…¥è®¨è®º</p>
    """, unsafe_allow_html=True)
    
    conflicts_detected = conflict_data.get("conflict_detected", False)
    
    # åˆ›å»ºå¤§å¡ç‰‡
    conflict_color = "#ffebee" if conflicts_detected else "#e8f5e8"
    border_color = "#f44336" if conflicts_detected else "#4caf50"
    icon = "ğŸ”´" if conflicts_detected else "ğŸŸ¢"
    status_text = "æ£€æµ‹åˆ°ä¸“å®¶æ„è§å­˜åœ¨æ˜¾è‘—åˆ†æ­§" if conflicts_detected else "ä¸“å®¶æ„è§åŸºæœ¬ä¸€è‡´ï¼Œæ— æ˜¾è‘—å†²çª"
    
    st.markdown(f"""
    <div style="
        background: {conflict_color};
        border: 2px solid {border_color};
        border-radius: 15px;
        padding: 20px;
        margin: 10px 0;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    ">
        <div style="text-align: center; margin-bottom: 15px;">
            <h3 style="margin: 0; color: {border_color};">{icon} å†²çªæ£€æµ‹ç»“æœ</h3>
            <p style="margin: 5px 0; font-size: 16px; color: #333;">{status_text}</p>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # åˆ†æè¯¦æƒ…
    if "conflict_analysis" in conflict_data:
        analysis = conflict_data["conflict_analysis"]
        
        col1, col2 = st.columns([3, 1])
        with col1:
            with st.expander("æŸ¥çœ‹è¯¦ç»†åˆ†æ", expanded=False):
                st.write("**å†²çªåˆ†æè¯¦æƒ…ï¼š**")
                if isinstance(analysis, str):
                    rendered_analysis = render_markdown_content(analysis)
                    st.markdown(rendered_analysis, unsafe_allow_html=True)
                elif isinstance(analysis, dict):
                    analysis_text = analysis.get('response', 'æ— åˆ†æç»“æœ')
                    rendered_analysis = render_markdown_content(analysis_text)
                    st.markdown(rendered_analysis, unsafe_allow_html=True)
                else:
                    st.write('æ— åˆ†æç»“æœ')
        
        with col2:
            consensus_score = conflict_data.get('consensus_score', 0.0)
            st.metric(
                "åˆæ­¥å…±è¯†åº¦", 
                f"{consensus_score:.2f}",
                delta=f"{consensus_score - 0.5:.2f}" if consensus_score != 0.5 else None,
                help="åŸºäºä¸“å®¶æ„è§ä¸€è‡´æ€§è®¡ç®—çš„å…±è¯†åº¦åˆ†æ•°"
            )
    
    st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("---")

def display_multi_round_discussion(multi_round_data: Dict[str, Any], selected_experts: List[str]):
    """æ˜¾ç¤ºå¤šè½®æ·±å…¥è®¨è®º"""
    total_rounds = multi_round_data.get("total_rounds", 0)
    
    if total_rounds > 0:
        st.markdown(f"""
        <div class=\"phase-wide-card\">
            <h3 class=\"section-title\">ğŸ’¬ å¤šè½®æ·±å…¥è®¨è®º</h3>
            <p class=\"sub-note\">ç»è¿‡å†²çªæ£€æµ‹ï¼Œä¸“å®¶ä»¬è¿›è¡Œäº† <strong>{total_rounds}è½®</strong> æ·±å…¥è®¨è®ºä»¥å¯»æ±‚å…±è¯†</p>
        """, unsafe_allow_html=True)
        
        rounds = multi_round_data.get("rounds", [])
        
        # åˆ›å»ºè½®æ¬¡é€‰æ‹©å™¨
        round_tabs = st.tabs([f"ç¬¬{i+1}è½®è®¨è®º" for i in range(total_rounds)])
        
        for i, round_data in enumerate(rounds):
            with round_tabs[i]:
                round_num = round_data.get("round", i+1)
                round_consensus = round_data.get("consensus_score", 0.0)
                
                # è½®æ¬¡æ¦‚è¦
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"#### ç¬¬ {round_num} è½®è®¨è®ºç»“æœ")
                with col2:
                    consensus_color = "#4caf50" if round_consensus > 0.7 else "#ff9800" if round_consensus > 0.5 else "#f44336"
                    st.markdown(f"""
                    <div style="
                        background: {consensus_color};
                        color: white;
                        padding: 10px;
                        border-radius: 10px;
                        text-align: center;
                    ">
                        <strong>å…±è¯†åº¦: {round_consensus:.2f}</strong>
                    </div>
                    """, unsafe_allow_html=True)
                
                # ä¸“å®¶å¡ç‰‡ - è¿‡æ»¤åªæ˜¾ç¤ºé€‰ä¸­çš„ä¸“å®¶
                round_results = round_data.get("results", {})
                
                # è¿‡æ»¤æ•°æ®
                filtered_round_results = {}
                for key, value in round_results.items():
                    expert_found = False
                    for expert_name in selected_experts:
                        possible_keys = EXPERT_NAME_MAPPING.get(expert_name, [expert_name])
                        if key in possible_keys or expert_name in key:
                            filtered_round_results[key] = value
                            expert_found = True
                            break
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œæ£€æŸ¥ agent å­—æ®µ
                    if not expert_found and isinstance(value, dict):
                        agent_name = value.get('agent', '')
                        for expert_name in selected_experts:
                            if expert_name in agent_name or any(keyword in agent_name for keyword in EXPERT_NAME_MAPPING.get(expert_name, [])):
                                filtered_round_results[key] = value
                                break

                agent_list = list(filtered_round_results.items())

                # å“åº”å¼å¸ƒå±€ï¼ˆä¿æŠ¤ç©ºæ•°æ®ï¼‰
                num_agents = len(agent_list)
                if num_agents == 0:
                    st.info("è¯¥è½®æš‚æ— åŒ¹é…çš„ä¸“å®¶å‘è¨€ã€‚")
                    continue
                cols_per_row = min(3, num_agents)

                # åˆ†æ‰¹æ˜¾ç¤ºå¡ç‰‡
                for k in range(0, num_agents, cols_per_row):
                    batch = agent_list[k:k + cols_per_row]
                    cols = st.columns(len(batch))
                    
                    for l, (agent_name, response) in enumerate(batch):
                        with cols[l]:
                            display_expert_card(response, k + l, f"round_{round_num}", round_num)
    else:
        st.markdown("### âœ… ä¸“å®¶æ„è§ä¸€è‡´")
        st.info("ğŸ‰ ä¸“å®¶ä»¬çš„åˆæ­¥æ„è§å·²ç»éå¸¸ä¸€è‡´ï¼Œæ— éœ€è¿›è¡Œå¤šè½®æ·±å…¥è®¨è®º")
    
    st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("---")

def display_consensus_evaluation(consensus_data: Dict[str, Any]):
    """æ˜¾ç¤ºå…±è¯†è¯„ä¼° (å…¨å®½ä¸“ä¸šå¡ç‰‡æ ·å¼)"""
    st.markdown("""
    <div class="phase-wide-card">
        <h3 class="section-title">ğŸ“Š å…±è¯†è¯„ä¼°</h3>
        <p class="sub-note">å¯¹ä¸“å®¶è®¨è®ºçš„æœ€ç»ˆç»“æœè¿›è¡Œå…±è¯†ç¨‹åº¦è¯„ä¼°</p>
    """, unsafe_allow_html=True)
    
    consensus_reached = consensus_data.get("consensus_reached", False)
    consensus_score = consensus_data.get("consensus_score", 0.0)
    threshold = consensus_data.get("threshold", 0.75)
    
    # åˆ›å»ºå…±è¯†è¯„ä¼°å¡ç‰‡
    consensus_color = "#e8f5e8" if consensus_reached else "#fff8e1"
    border_color = "#4caf50" if consensus_reached else "#ffb300"
    icon = "âœ…" if consensus_reached else "âš ï¸"
    status_text = "ä¸“å®¶å·²è¾¾æˆå…±è¯†" if consensus_reached else "ä»éœ€è¿›ä¸€æ­¥åè°ƒ"

    st.markdown(f"""
    <div style="
        background: {consensus_color};
        border: 2px solid {border_color};
        border-radius: 16px;
        padding: 22px 26px 18px 26px;
        margin: 18px 0 10px 0;
        box-shadow: 0 4px 10px rgba(0,0,0,0.08);
    ">
        <h3 style="margin: 0 0 8px 0; color: {border_color}; text-align:center;">{icon} å…±è¯†è¯„ä¼°ç»“æœ</h3>
        <p style="margin: 0 0 12px 0; font-size: 16px; color: #333; text-align:center;">{status_text}</p>
    </div>
    """, unsafe_allow_html=True)

    # æŒ‡æ ‡åŒº
    mcol1, mcol2, mcol3 = st.columns(3)
    with mcol1:
        st.metric("æœ€ç»ˆå…±è¯†åº¦", f"{consensus_score:.2f}")
    with mcol2:
        st.metric("å…±è¯†é˜ˆå€¼", f"{threshold:.2f}")
    with mcol3:
        gap = consensus_score - threshold
        st.metric("é«˜äºé˜ˆå€¼" if gap >= 0 else "ä½äºé˜ˆå€¼", f"{gap:+.2f}")
    
    # è¿›åº¦æ¡è¡¨ç¤ºç¨‹åº¦
    pct = min(max(consensus_score / max(threshold, 1e-6), 0), 1.5)
    st.progress(min(pct, 1.0))
    
    # è¯„ä¼°è¯¦æƒ…
    detail_block = None
    if "evaluation" in consensus_data:
        detail_block = consensus_data["evaluation"]
    elif "evaluation_details" in consensus_data:
        detail_block = {"response": consensus_data["evaluation_details"]}

    if detail_block:
        with st.expander("æŸ¥çœ‹è¯¦ç»†è¯„ä¼°", expanded=False):
            st.write("**å…±è¯†è¯„ä¼°è¯¦æƒ…ï¼š**")
            if isinstance(detail_block, dict):
                st.write(detail_block.get('response', 'æ— è¯„ä¼°ç»“æœ'))
            else:
                st.write(str(detail_block))
    
    st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("---")

def display_final_coordination(coordination_result: Dict[str, Any]):
    """æ˜¾ç¤ºæœ€ç»ˆMDTåè°ƒå»ºè®® (å…¨å®½ä¸“ä¸šå¡ç‰‡æ ·å¼)"""
    st.markdown("""
    <div class="phase-wide-card">
        <h3 class="section-title">ğŸ¯ æœ€ç»ˆMDTåè°ƒå»ºè®®</h3>
        <p class="sub-note">åŸºäºæ•´ä¸ªè®¨è®ºè¿‡ç¨‹ï¼ŒMDTåè°ƒå‘˜ç”Ÿæˆçš„ç»¼åˆä¸´åºŠå»ºè®®</p>
    """, unsafe_allow_html=True)
    
    # è·å–å…³é”®æŒ‡æ ‡
    final_consensus = coordination_result.get('consensus_score', 0.0)
    discussion_rounds = coordination_result.get('discussion_rounds', 0)
    consensus_reached = coordination_result.get('consensus_reached', False)
    
    # çŠ¶æ€æŒ‡ç¤ºæ¡
    status_color = "#4caf50" if consensus_reached else "#ff9800"
    status_icon = "âœ…" if consensus_reached else "âš ï¸"
    status_text = "å·²è¾¾æˆä¸“å®¶å…±è¯†" if consensus_reached else "å­˜åœ¨ä¸€å®šåˆ†æ­§"
    
    # å…³é”®æŒ‡æ ‡å±•ç¤º
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        ">
            <h2 style="margin: 0;">{final_consensus:.2f}</h2>
            <p style="margin: 5px 0;">æœ€ç»ˆå…±è¯†åº¦</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        ">
            <h2 style="margin: 0;">{discussion_rounds}</h2>
            <p style="margin: 5px 0;">è®¨è®ºè½®æ•°</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div style="
            background: {status_color};
            color: white;
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        ">
            <h2 style="margin: 0;">{status_icon}</h2>
            <p style="margin: 5px 0;">{status_text}</p>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆå»ºè®®å†…å®¹
    st.markdown("#### ğŸ“‹ åè°ƒå‘˜ç»¼åˆå»ºè®®")
    
    response_text = coordination_result.get('response', 'æ— å“åº”')
    agent_name = coordination_result.get('agent', 'MDTåè°ƒå‘˜')
    
    # ä½¿ç”¨ç¾è§‚çš„å®¹å™¨å±•ç¤ºå»ºè®®å†…å®¹
    st.markdown(f"""
    <div style="
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 3px;
        border-radius: 15px;
        margin: 10px 0;
    ">
        <div style="
            background: white;
            padding: 25px;
            border-radius: 12px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        ">
            <div style="
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 10px 20px;
                border-radius: 10px;
                text-align: center;
                margin-bottom: 20px;
            ">
                <h4 style="margin: 0;">{agent_name}</h4>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # åœ¨HTMLä¸‹æ–¹ç´§æ¥ç€ç”¨Markdownæ¸²æŸ“å®é™…å†…å®¹
    rendered_response = render_markdown_content(response_text)
    st.markdown(rendered_response, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("---")

def display_expert_card(response: Dict[str, Any], color_index: int, card_type: str, round_num: Optional[int] = None):
    """æ˜¾ç¤ºä¸“å®¶å¡ç‰‡"""
    agent_display_name = response.get('agent', 'Unknown Expert')
    specialty = response.get('specialty', 'ä¸“ç§‘åŒ»ç”Ÿ')
    
    # ç”Ÿæˆä¸åŒçš„é¢œè‰²
    if card_type == "individual":
        colors = ["#667eea", "#f093fb", "#4facfe", "#43e97b", "#fa709a", "#a8edea", "#ff9a9e"]
    elif card_type == "sharing":
        colors = ["#f093fb", "#4facfe", "#43e97b", "#fa709a", "#a8edea", "#ff9a9e", "#667eea"]
    else:  # multi-round
        colors = ["#9c27b0", "#3f51b5", "#009688", "#ff5722", "#795548", "#607d8b", "#e91e63"]
    
    color = colors[color_index % len(colors)]
    
    # åˆ›å»ºå¡ç‰‡ 
    response_text = response.get('response', 'æ— å“åº”')
    timestamp = response.get('timestamp', '')
    if timestamp:
        try:
            dt = datetime.fromisoformat(timestamp)
            formatted_time = dt.strftime('%H:%M:%S')
        except:
            formatted_time = timestamp
    else:
        formatted_time = 'N/A'
    
    # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
    import html
    import re
    cleaned_response = re.sub(r"<\/?(script|iframe|style)[^>]*>", "", response_text, flags=re.IGNORECASE)
    safe_name = html.escape(agent_display_name)
    safe_specialty = html.escape(specialty)
    
    # è§„èŒƒåŒ–å¤šä½™ç©ºè¡Œ
    cleaned_response = re.sub(r"\n{3,}", "\n\n", cleaned_response).strip()
    
    # åˆ›å»ºå¡ç‰‡å¤´éƒ¨
    st.markdown(f"""
    <div style="
        background: white;
        border-radius: 15px;
        margin-bottom: 20px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        overflow: hidden;
        border: 1px solid #e0e0e0;
    ">
        <div style="background: {color}; color: white; padding: 15px; text-align: center;">
            <h4 style="margin: 0; color: white; font-size: 16px;">{safe_name}</h4>
            <p style="margin: 5px 0 0 0; color: rgba(255,255,255,0.9); font-size: 12px;">{safe_specialty}</p>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # åœ¨å¡ç‰‡ä¸‹æ–¹ç´§æ¥ç€æ·»åŠ ç™½è‰²èƒŒæ™¯çš„å†…å®¹åŒºåŸŸ
    with st.container():
        # ä½¿ç”¨ç®€åŒ–çš„å®¹å™¨ï¼Œé¿å…æ ·å¼å†²çª
        rendered_content = render_markdown_content(cleaned_response)
        
        # åˆ›å»ºå®Œæ•´çš„å¡ç‰‡å†…å®¹åŒºåŸŸ
        st.markdown(f"""
        <div style="
            background: white;
            padding: 20px;
            margin-top: -20px;
            margin-bottom: 20px;
            border-radius: 0 0 15px 15px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
            border: 1px solid #e0e0e0;
            border-top: none;
        ">
                <div class="card-scroll">{rendered_content}</div>
            <div style="border-top:1px solid #eee; padding-top:10px; margin-top:15px;">
                <small style="color:#666;">æ—¶é—´: {formatted_time}</small>
            </div>
        </div>
        """, unsafe_allow_html=True)

def display_download_section(result: Dict[str, Any], case_data: Dict[str, Any]):
    """æ˜¾ç¤ºä¸‹è½½ç»“æœéƒ¨åˆ†"""
    st.subheader("ğŸ’¾ å¯¼å‡ºç»“æœ")
    
    # å‡†å¤‡ä¸‹è½½æ•°æ®
    download_data = json.dumps(result, ensure_ascii=False, indent=2)
    
    col1, col2 = st.columns(2)
    with col1:
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœ(JSON)",
            data=download_data,
            file_name=f"mdt_result_{result.get('session_id', 'unknown')}.json",
            mime="application/json"
        )
    
    with col2:
        # ç”Ÿæˆç®€åŒ–æŠ¥å‘Š
        phases = result.get("phases", {})
        if "final_coordination" in phases:
            final_recommendation = phases["final_coordination"].get('response', '')
            st.download_button(
                label="ğŸ“‹ ä¸‹è½½MDTæŠ¥å‘Š(TXT)",
                data=f"""MDTè®¨è®ºæŠ¥å‘Š
=================
ç‰ˆæœ¬: 1.0
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ä¸€ã€åŸºæœ¬ä¿¡æ¯
--------------------------------
æ‚£è€…ID        : {case_data.get('patient_id', 'N/A')}
è®¨è®ºå¼€å§‹æ—¶é—´  : {result.get('start_time', 'N/A')}
å‚ä¸ä¸“å®¶ï¼ˆ{len(result.get('participants', []))}äººï¼‰: {', '.join(result.get('participants', []))}

äºŒã€æœ€ç»ˆç»¼åˆå»ºè®®
--------------------------------
{final_recommendation}

ä¸‰ã€é˜¶æ®µæ€§æ‘˜è¦ï¼ˆæå–ï¼‰
--------------------------------
1. å†²çªæ£€æµ‹ç»“æœ: {result.get('phases', {}).get('conflict_detection', {}).get('conflict_analysis','N/A') if isinstance(result.get('phases', {}).get('conflict_detection', {}), dict) else 'N/A'}
2. å…±è¯†è¯„ä¼°: å…±è¯†åº¦ {result.get('phases', {}).get('consensus_evaluation', {}).get('consensus_score','N/A')} é˜ˆå€¼ {result.get('phases', {}).get('consensus_evaluation', {}).get('threshold','N/A')}
3. è®¨è®ºè½®æ•°: {result.get('phases', {}).get('multi_round_discussion', {}).get('total_rounds','0')}

å››ã€æŠ€æœ¯å…ƒæ•°æ®
--------------------------------
ä¼šè¯ID        : {result.get('session_id','N/A')}
æ€»æ—¶é•¿        : {result.get('duration','N/A')}
å·¥å…·ç‰ˆæœ¬      : MDT Orchestrator v1

ï¼ˆæœ¬æŠ¥å‘Šä¸ºè‡ªåŠ¨ç”Ÿæˆï¼Œä¾›ä¸´åºŠå‚è€ƒï¼Œä¸æ›¿ä»£ä¸´åºŠåŒ»å¸ˆæœ€ç»ˆåˆ¤æ–­ã€‚ï¼‰
""",
                file_name=f"mdt_report_{result.get('session_id', 'unknown')}.txt",
                mime="text/plain"
            )

# run_stream_mdt åŒ…è£…å‡½æ•°å·²ç§»é™¤ï¼Œç›´æ¥è°ƒç”¨ run_real_stream_mdt

def run_real_stream_mdt(selected_experts: List[str]):
    """è¿è¡ŒMDTè®¨è®ºï¼ˆä½¿ç”¨AIæ¨¡å‹ï¼‰ - å«åŠ¨æ€æµç¨‹ä¸åä½œå›¾"""
    st.info("ğŸ¤– æ­£åœ¨è¿›è¡ŒMDTå¤šå­¦ç§‘è®¨è®º")

    try:
        orchestrator = MDTOrchestrator()
        st.session_state['active_orchestrator'] = orchestrator  # ä¿å­˜å¼•ç”¨ä¾› RAG ç‰‡æ®µå±•ç¤º
        case_data = st.session_state.get("case_data", {})
        full_case_data = case_data.get("full_case_data", {})
        if full_case_data:
            merged_case_data = {**full_case_data, **case_data}
            merged_case_data.pop("full_case_data", None)
            case_data = merged_case_data

        current_containers: Dict[str, Any] = {}
        phase_container = None
        created_in_phase = 0
        cols_current_row: List[Any] = []

        progress_bar = st.progress(0)
        metrics_container = st.empty()
        phase_progress_map = {
            "initialization": 0.02,
            "individual_analysis": 0.18,
            "sharing_discussion": 0.35,
            "conflict_detection": 0.50,
            "multi_round_discussion": 0.70,
            "consensus_evaluation": 0.85,
            "final_coordination": 0.95,
            "completed": 1.0
        }

        collected_result = {
            "session_id": f"MDT_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "participants": selected_experts,
            "start_time": datetime.now().isoformat(),
            "phases": {}
        }

        flow_placeholder = st.empty()
        interaction_placeholder = st.empty()
        flow_steps_order = [
            ("individual_analysis", "ç‹¬ç«‹åˆ†æ", "ä¸“å®¶ç‹¬ç«‹åˆè¯„"),
            ("sharing_discussion", "åˆæ­¥è®¨è®º", "è§‚ç‚¹å…±äº«"),
            ("conflict_detection", "å†²çªæ£€æµ‹", "è¯†åˆ«å·®å¼‚"),
            ("multi_round_discussion", "å¤šè½®è®¨è®º", "è¿­ä»£æ±‚åŒ"),
            ("consensus_evaluation", "å…±è¯†è¯„ä¼°", "é‡åŒ–ä¸€è‡´æ€§"),
            ("final_coordination", "æœ€ç»ˆåè°ƒ", "ç»¼åˆå»ºè®®")
        ]
        flow_state = {k: {"status": "pending", "agents": set(), "rounds": 0, "metrics": {}} for k,_,_ in flow_steps_order}

        interaction_nodes: List[str] = []
        interaction_edges: Dict[tuple, int] = {}
        last_speaker: Optional[str] = None
        coordinator_names = [n for n in EXPERT_NAME_MAPPING if 'åè°ƒå‘˜' in n]

        def ensure_node(name: str):
            if name not in interaction_nodes:
                interaction_nodes.append(name)

        def add_edge(src: str, dst: str):
            if not src or not dst or src == dst:
                return
            key = (src, dst)
            interaction_edges[key] = interaction_edges.get(key, 0) + 1

        def build_interaction_svg() -> str:
            if not interaction_nodes:
                return ""
            import math
            n = len(interaction_nodes)
            cx, cy = 300, 300
            radius = 210 if n <= 8 else 260
            positions = {}
            for i, node in enumerate(interaction_nodes):
                angle = 2 * math.pi * i / n - math.pi/2
                x = cx + radius * math.cos(angle)
                y = cy + radius * math.sin(angle)
                positions[node] = (x, y)
            max_w = max(interaction_edges.values()) if interaction_edges else 1
            svg_parts = ["<svg viewBox='0 0 600 600' width='100%' height='420' class='mdt-graph-svg' style='background:linear-gradient(145deg,#ffffff,#f5f7fb);border:1px solid #e1e5ec;border-radius:18px;'>"]
            svg_parts.append("<defs><marker id='arrow' markerWidth='10' markerHeight='10' refX='10' refY='5' orient='auto' markerUnits='strokeWidth'><path d='M0,0 L10,5 L0,10 z' fill='#556' /></marker></defs>")
            for (src, dst), cnt in interaction_edges.items():
                x1,y1 = positions.get(src, (0,0))
                x2,y2 = positions.get(dst, (0,0))
                width = 1.5 + 4.5 * (cnt / max_w)
                opacity = 0.35 + 0.55 * (cnt / max_w)
                svg_parts.append(f"<line x1='{x1}' y1='{y1}' x2='{x2}' y2='{y2}' stroke='#667eea' stroke-width='{width:.2f}' stroke-linecap='round' opacity='{opacity:.2f}' marker-end='url(#arrow)' />")
            for node,(x,y) in positions.items():
                color = get_expert_color(node)
                abbrev = node.replace('ä¸“å®¶','').replace('åŒ»ç”Ÿ','').replace('MDT','')[:4]
                svg_parts.append(f"<g><circle cx='{x}' cy='{y}' r='34' fill='{color}' stroke='white' stroke-width='3' opacity='0.92' />")
                svg_parts.append(f"<text x='{x}' y='{y+4}' font-size='13' fill='white' text-anchor='middle' font-weight='600' style='font-family:-apple-system,BlinkMacSystemFont,Roboto,Arial;'>{abbrev}</text></g>")
            svg_parts.append("</svg>")
            legend = "<div style='margin-top:6px;font-size:12px;color:#566176;'>ç®­å¤´è¡¨ç¤ºä¿¡æ¯/å‚è€ƒæ–¹å‘ï¼›çº¿æ¡è¶Šç²—è¡¨ç¤ºè¯¥æ–¹å‘äº’åŠ¨æ¬¡æ•°è¶Šå¤šã€‚</div>"
            return "<div class='mdt-flow-wrapper' style='padding:14px 20px;'>" \
                   + "<h4 style='margin:4px 0 12px 4px;font-weight:700;font-size:16px;color:#2d3e50;'>ğŸ¤ æ™ºèƒ½ä½“åä½œäº’åŠ¨å›¾ (å®æ—¶)</h4>" \
                   + ''.join(svg_parts) + legend + "</div>"

        def render_interaction():
            interaction_placeholder.markdown(build_interaction_svg(), unsafe_allow_html=True)

        def render_flow():
            html_blocks = ["<div class='mdt-flow-wrapper'><div class='mdt-flow-steps'>"]
            for idx,(key,title,desc) in enumerate(flow_steps_order, start=1):
                st_info = flow_state[key]
                status = st_info["status"]
                norm_agents = []
                for a in st_info["agents"]:
                    na = a.replace('ä¸“å®¶','').replace('MDT','').replace('åŒ»ç”Ÿ','').strip() or a
                    norm_agents.append(na)
                agents_preview = ", ".join(list(norm_agents)[:3])
                rounds_txt = f"è½®æ¬¡: {st_info['rounds']}" if st_info['rounds'] else ""
                metrics_html = ""
                if st_info["metrics"]:
                    badges = []
                    for mk, mv in st_info["metrics"].items():
                        if mv is None: continue
                        if isinstance(mv, float):
                            mv_fmt = f"{mv:.2f}" if abs(mv) < 1000 else f"{mv:.1e}"
                        else:
                            mv_fmt = str(mv)
                        badges.append(f"<span class='mdt-flow-badge'>{mk}:{mv_fmt}</span>")
                    if badges:
                        metrics_html = f"<div class='mdt-flow-metrics'>{''.join(badges)}</div>"
                agents_html = f"<div class='mdt-flow-active-agents'>{agents_preview}{'â€¦' if len(st_info['agents'])>3 else ''}</div>" if agents_preview else ""
                rounds_html = f"<div class='mdt-flow-rounds'>{rounds_txt}</div>" if rounds_txt else ""
                html_blocks.append(
                    f"<div class='mdt-flow-step {status}'>"
                    f"<div class='mdt-flow-circle {status}'>{idx}</div>"
                    f"<p class='mdt-flow-title'>{title}</p>"
                    f"<p class='mdt-flow-desc'>{desc}</p>"
                    f"{rounds_html}{agents_html}{metrics_html}"
                    f"</div>"
                )
            html_blocks.append("</div></div>")
            flow_placeholder.markdown("".join(html_blocks), unsafe_allow_html=True)

        # åˆæ¬¡æ˜¾ç¤º
        render_flow(); render_interaction()

        for stream_result in orchestrator.conduct_mdt_session_stream(case_data, selected_experts):
            rtype = stream_result.get("type")
            phase = stream_result.get("phase")

            if rtype == "phase_start":
                st.markdown("---")
                phase_desc = {
                    "individual_analysis": "å„ä¸“ç§‘ç‹¬ç«‹åˆ†æ",
                    "sharing_discussion": "ä¸“ç§‘é—´åˆæ­¥è®¨è®º",
                    "conflict_detection": "æ„è§å†²çªæ£€æµ‹",
                    "multi_round_discussion": "å¤šè½®æ·±å…¥è®¨è®º",
                    "consensus_evaluation": "å…±è¯†è¯„ä¼°",
                    "final_coordination": "æœ€ç»ˆåè°ƒå»ºè®®"
                }
                phase_name = phase or "æœªçŸ¥é˜¶æ®µ"
                render_phase_header(phase_desc.get(phase_name, phase_name), stream_result.get("message", ""))
                current_containers = {}
                phase_container = st.container()
                created_in_phase = 0
                cols_current_row = []
                progress_bar.progress(phase_progress_map.get(phase_name, 0.0))
                for k in flow_state:
                    if flow_state[k]["status"] == "current":
                        flow_state[k]["status"] = "done"
                if phase_name in flow_state:
                    flow_state[phase_name]["status"] = "current"
                render_flow()
                last_speaker = None

            elif rtype == "agent_start":
                expert_name = stream_result.get("agent", "ä¸“å®¶")
                if not is_expert_selected(expert_name, selected_experts):
                    continue
                if expert_name not in current_containers:
                    if created_in_phase % 3 == 0:
                        if phase_container is None:
                            phase_container = st.container()
                        cols_current_row = phase_container.columns(3)
                    target_col = cols_current_row[created_in_phase % 3]
                    current_containers[expert_name] = target_col.empty()
                    created_in_phase += 1
                display_expert_response(current_containers[expert_name], expert_name, "", "thinking")
            elif rtype == "agent_chunk":
                expert_name = stream_result.get("agent", "ä¸“å®¶")
                if not is_expert_selected(expert_name, selected_experts):
                    continue
                full_response = stream_result.get("full_response") or ""
                if expert_name not in current_containers:
                    if created_in_phase % 3 == 0:
                        if phase_container is None:
                            phase_container = st.container()
                        cols_current_row = phase_container.columns(3)
                    target_col = cols_current_row[created_in_phase % 3]
                    current_containers[expert_name] = target_col.empty()
                    created_in_phase += 1
                display_expert_response(current_containers[expert_name], expert_name, full_response, "typing")
                display_expert_response(current_containers[expert_name], expert_name, full_response, "typing")

            elif rtype == "phase_complete":
                phase_name = stream_result.get("phase")
                phase_result = stream_result.get("result", {})
                if phase_name:
                    collected_result["phases"][phase_name] = phase_result
                if phase_name in flow_state:
                    flow_state[phase_name]["status"] = "done"
                    metrics_capture = {}
                    if phase_name == "conflict_detection":
                        metrics_capture = {"å…±è¯†": phase_result.get("consensus_score"), "å†²çª": "æ˜¯" if phase_result.get("conflict_detected") else "å¦"}
                    elif phase_name == "consensus_evaluation":
                        metrics_capture = {"æœ€ç»ˆå…±è¯†": phase_result.get("consensus_score"), "é˜ˆå€¼": phase_result.get("threshold")}
                    elif phase_name == "multi_round_discussion":
                        metrics_capture = {"è½®æ•°": phase_result.get("total_rounds")}
                    flow_state[phase_name]["metrics"] = metrics_capture
                    if phase_name == "multi_round_discussion":
                        flow_state[phase_name]["rounds"] = phase_result.get("total_rounds", 0)
                render_flow()
                if phase_name == "conflict_detection":
                    consensus_score = phase_result.get("consensus_score", 0.0)
                    conflicts = phase_result.get("conflict_detected", False)
                    with metrics_container.container():
                        c1, c2 = st.columns(2)
                        with c1: st.metric("åˆæ­¥å…±è¯†åº¦", f"{consensus_score:.2f}")
                        with c2: st.metric("æ˜¯å¦å­˜åœ¨å†²çª", "æ˜¯" if conflicts else "å¦")
                elif phase_name == "consensus_evaluation":
                    consensus_score = phase_result.get("consensus_score", 0.0)
                    threshold = phase_result.get("threshold", 0.75)
                    gap = consensus_score - threshold
                    with metrics_container.container():
                        c1, c2, c3 = st.columns(3)
                        with c1: st.metric("æœ€ç»ˆå…±è¯†åº¦", f"{consensus_score:.2f}")
                        with c2: st.metric("å…±è¯†é˜ˆå€¼", f"{threshold:.2f}")
                        with c3: st.metric("é«˜äºé˜ˆå€¼" if gap >= 0 else "ä½äºé˜ˆå€¼", f"{gap:+.2f}")
                if phase_name in ("conflict_detection", "consensus_evaluation", "final_coordination"):
                    coord_nodes = [n for n in interaction_nodes if any(cn in n for cn in coordinator_names)]
                    if coord_nodes:
                        coord = coord_nodes[0]
                        for n in interaction_nodes:
                            if n != coord:
                                add_edge(n, coord)
                        render_interaction()

            elif rtype == "agent_complete":
                expert_name = stream_result.get("agent", "ä¸“å®¶")
                if not is_expert_selected(expert_name, selected_experts):
                    continue
                full_response = stream_result.get("result", {}).get("response", "")
                if expert_name not in current_containers:
                    if created_in_phase % 3 == 0:
                        if phase_container is None:
                            phase_container = st.container()
                        cols_current_row = phase_container.columns(3)
                    target_col = cols_current_row[created_in_phase % 3]
                    current_containers[expert_name] = target_col.empty()
                    created_in_phase += 1
                display_expert_response(current_containers[expert_name], expert_name, full_response, "complete")
                ensure_node(expert_name)
                last_speaker = expert_name
                render_interaction()

            elif rtype == "session_complete":
                st.success("ğŸ‰ MDTè®¨è®ºå®Œæˆï¼")
                progress_bar.progress(1.0)
                for k in flow_state:
                    if flow_state[k]["status"] == "current":
                        flow_state[k]["status"] = "done"
                render_flow(); render_interaction()
                final_result = stream_result.get("result", {})
                if final_result:
                    collected_result.update(final_result)
                # ç»Ÿä¸€å±•ç¤ºæ‰€æœ‰ä¸“å®¶çš„ RAG ç‰‡æ®µé¢„è§ˆï¼ˆæ±‡æ€»è‡³åº•éƒ¨ï¼‰
                orch = st.session_state.get('active_orchestrator')
                if orch and hasattr(orch, 'agents'):
                    name_map = {
                        'pulmonary':'å‘¼å¸ç§‘ä¸“å®¶','imaging':'å½±åƒç§‘ä¸“å®¶','pathology':'ç—…ç†ç§‘ä¸“å®¶',
                        'rheumatology':'é£æ¹¿å…ç–«ç§‘ä¸“å®¶','data_analysis':'æ•°æ®åˆ†æä¸“å®¶','coordinator':'åè°ƒå‘˜'
                    }
                    rag_any = False
                    rag_container = st.container()
                    with rag_container:
                        with st.expander('ğŸ” RAGç‰‡æ®µ(é¢„è§ˆ) - å…¨éƒ¨ä¸“å®¶æ±‡æ€»', expanded=False):
                            for key, agent in orch.agents.items():
                                chunks = getattr(agent, 'last_retrieved_chunks', []) or []
                                if chunks:
                                    rag_any = True
                                    st.markdown(f"### {name_map.get(key, key)}")
                                    for idx, chunk in enumerate(chunks[:5], 1):
                                        # å…¼å®¹å­—ç¬¦ä¸²æ—§æ ¼å¼ä¸æ–°ç»“æ„åŒ–å­—å…¸
                                        if isinstance(chunk, dict):
                                            src = chunk.get('source','æœªçŸ¥')
                                            score = chunk.get('score')
                                            content = chunk.get('raw') or chunk.get('content','')
                                            meta = f"æ¥æº: {src}"
                                            if score is not None:
                                                meta += f" | ç›¸å…³åº¦: {score:.4f}" if isinstance(score,(int,float)) else ""
                                            st.markdown(f"**#{idx}** {meta}")
                                            st.code(content[:800], language='markdown')
                                        else:
                                            st.markdown(f"**#{idx}**")
                                            st.code(str(chunk)[:600], language='markdown')
                            if not rag_any:
                                st.info('å½“å‰ä¼šè¯æœªæ£€ç´¢åˆ°ä»»ä½•RAGç‰‡æ®µã€‚')
                end_time = datetime.now()
                collected_result["end_time"] = end_time.isoformat()
                start_time = datetime.fromisoformat(collected_result["start_time"])
                duration = end_time - start_time
                collected_result["duration"] = f"{int(duration.total_seconds()//60)}åˆ†{int(duration.total_seconds()%60)}ç§’"
                st.session_state.mdt_result = collected_result
                st.session_state.stream_complete = True
                break

            elif rtype == "session_error":
                st.error(f"âŒ è®¨è®ºè¿‡ç¨‹å‡ºç°é”™è¯¯ï¼š{stream_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                st.session_state.stream_complete = True
                break

    except Exception as e:
        st.error(f"âŒ MDTè®¨è®ºæ‰§è¡Œå¤±è´¥ï¼š{e}")
        logger.error(f"Stream MDT error: {e}")
        st.session_state.stream_complete = True

if __name__ == "__main__":
    main()
